{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are expected to use this support code if you are writing code in Python.\n",
    "# You may want to write:\n",
    "# from ct_support_code import *\n",
    "# at the top of your answers\n",
    "\n",
    "# You will need numpy and scipy:\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def params_unwrap(param_vec, shapes, sizes):\n",
    "    \"\"\"Helper routine for minimize_list\"\"\"\n",
    "    args = []\n",
    "    pos = 0\n",
    "    for i in range(len(shapes)):\n",
    "        sz = sizes[i]\n",
    "        args.append(param_vec[pos:pos+sz].reshape(shapes[i]))\n",
    "        pos += sz\n",
    "    return args\n",
    "\n",
    "def params_wrap(param_list):\n",
    "    \"\"\"Helper routine for minimize_list\"\"\"\n",
    "    param_list = [np.array(x) for x in param_list]\n",
    "    shapes = [x.shape for x in param_list]\n",
    "    sizes = [x.size for x in param_list]\n",
    "    param_vec = np.zeros(sum(sizes))\n",
    "    pos = 0\n",
    "    for param in param_list:\n",
    "        sz = param.size\n",
    "        param_vec[pos:pos+sz] = param.ravel()\n",
    "        pos += sz\n",
    "    unwrap = lambda pvec: params_unwrap(pvec, shapes, sizes)\n",
    "    return param_vec, unwrap\n",
    "\n",
    "def minimize_list(cost, init_list, args):\n",
    "    \"\"\"Optimize a list of arrays (wrapper of scipy.optimize.minimize)\n",
    "\n",
    "    The input function \"cost\" should take a list of parameters,\n",
    "    followed by any extra arguments:\n",
    "        cost(init_list, *args)\n",
    "    should return the cost of the initial condition, and a list in the same\n",
    "    format as init_list giving gradients of the cost wrt the parameters.\n",
    "\n",
    "    The options to the optimizer have been hard-coded. You may wish\n",
    "    to change disp to True to get more diagnostics. You may want to\n",
    "    decrease maxiter while debugging. Although please report all results\n",
    "    in Q2-5 using maxiter=500.\n",
    "\n",
    "    The Matlab code comes with a different optimizer, so won't give the same\n",
    "    results.\n",
    "    \"\"\"\n",
    "    opt = {'maxiter': 500, 'disp': False}\n",
    "    init, unwrap = params_wrap(init_list)\n",
    "    def wrap_cost(vec, *args):\n",
    "        E, params_bar = cost(unwrap(vec), *args)\n",
    "        vec_bar, _ = params_wrap(params_bar)\n",
    "        return E, vec_bar\n",
    "    res = minimize(wrap_cost, init, args, 'L-BFGS-B', jac=True, options=opt)\n",
    "    return unwrap(res.x)\n",
    "\n",
    "\n",
    "def linreg_cost(params, X, yy, alpha):\n",
    "    \"\"\"Regularized least squares cost function and gradients\n",
    "\n",
    "    Can be optimized with minimize_list -- see fit_linreg_gradopt for a\n",
    "    demonstration.\n",
    "\n",
    "    Inputs:\n",
    "    params: tuple (ww, bb): weights ww (D,), bias bb scalar\n",
    "         X: N,D design matrix of input features\n",
    "        yy: N,  real-valued targets\n",
    "     alpha: regularization constant\n",
    "\n",
    "    Outputs: (E, [ww_bar, bb_bar]), cost and gradients\n",
    "    \"\"\"\n",
    "    # Unpack parameters from list\n",
    "    ww, bb = params\n",
    "\n",
    "    # forward computation of error\n",
    "    ff = np.dot(X, ww) + bb\n",
    "    res = ff - yy\n",
    "    E = np.dot(res, res) + alpha*np.dot(ww, ww)\n",
    "\n",
    "    # reverse computation of gradients\n",
    "    ff_bar = 2*res\n",
    "    bb_bar = np.sum(ff_bar)\n",
    "    ww_bar = np.dot(X.T, ff_bar) + 2*alpha*ww\n",
    "\n",
    "    return E, [ww_bar, bb_bar]\n",
    "\n",
    "def fit_linreg_gradopt(X, yy, alpha):\n",
    "    \"\"\"\n",
    "    fit a regularized linear regression model with gradient opt\n",
    "\n",
    "         ww, bb = fit_linreg_gradopt(X, yy, alpha)\n",
    "\n",
    "     Find weights and bias by using a gradient-based optimizer\n",
    "     (minimize_list) to improve the regularized least squares cost:\n",
    "\n",
    "       np.sum(((np.dot(X,ww) + bb) - yy)**2) + alpha*np.dot(ww,ww)\n",
    "\n",
    "     Inputs:\n",
    "             X N,D design matrix of input features\n",
    "            yy N,  real-valued targets\n",
    "         alpha     scalar regularization constant\n",
    "\n",
    "     Outputs:\n",
    "            ww D,  fitted weights\n",
    "            bb     scalar fitted bias\n",
    "    \"\"\"\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(linreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "\n",
    "def pca_zm_proj(X, K=None):\n",
    "    \"\"\"return PCA projection matrix for zero mean data\n",
    "\n",
    "    Inputs:\n",
    "        X N,D design matrix of input features -- must be zero mean\n",
    "        K     how many columns to return in projection matrix\n",
    "\n",
    "    Outputs:\n",
    "        V D,K matrix to apply to X or other matrices shifted in same way.\n",
    "    \"\"\"\n",
    "    if np.max(np.abs(np.mean(X,0))) > 1e-9:\n",
    "        raise ValueError('Data is not zero mean.')\n",
    "    if K is None:\n",
    "        K = X.shape[1]\n",
    "    E, V = np.linalg.eig(np.dot(X.T, X))\n",
    "    idx = np.argsort(E)[::-1]\n",
    "    V = V[:, idx[:K]] # D,K\n",
    "    return V\n",
    "\n",
    "\n",
    "def logreg_cost(params, X, yy, alpha):\n",
    "    \"\"\"Regularized logistic regression cost function and gradients\n",
    "\n",
    "    Can be optimized with minimize_list -- see fit_linreg_gradopt for a\n",
    "    demonstration of fitting a similar function.\n",
    "\n",
    "    Inputs:\n",
    "    params: tuple (ww, bb): weights ww (D,), bias bb scalar\n",
    "         X: N,D design matrix of input features\n",
    "        yy: N,  real-valued targets\n",
    "     alpha: regularization constant\n",
    "\n",
    "    Outputs: (E, [ww_bar, bb_bar]), cost and gradients\n",
    "    \"\"\"\n",
    "    # Unpack parameters from list\n",
    "    ww, bb = params\n",
    "\n",
    "    # Force targets to be +/- 1\n",
    "    yy = 2*(yy==1) - 1\n",
    "\n",
    "    # forward computation of error\n",
    "    aa = yy*(np.dot(X, ww) + bb)\n",
    "    sigma = 1/(1 + np.exp(-aa))\n",
    "    E = -np.sum(np.log(sigma)) + alpha*np.dot(ww, ww)\n",
    "\n",
    "    # reverse computation of gradients\n",
    "    aa_bar = sigma - 1\n",
    "    bb_bar = np.dot(aa_bar, yy)\n",
    "    ww_bar = np.dot(X.T, yy*aa_bar) + 2*alpha*ww\n",
    "\n",
    "    return E, (ww_bar, bb_bar)\n",
    "\n",
    "\n",
    "def nn_cost(params, X, yy=None, alpha=None):\n",
    "    \"\"\"NN_COST simple neural network cost function and gradients, or predictions\n",
    "\n",
    "           E, params_bar = nn_cost([ww, bb, V, bk], X, yy, alpha)\n",
    "                    pred = nn_cost([ww, bb, V, bk], X)\n",
    "\n",
    "     Cost function E can be minimized with minimize_list\n",
    "\n",
    "     Inputs:\n",
    "             params (ww, bb, V, bk), where:\n",
    "                    --------------------------------\n",
    "                        ww K,  hidden-output weights\n",
    "                        bb     scalar output bias\n",
    "                         V K,D hidden-input weights\n",
    "                        bk K,  hidden biases\n",
    "                    --------------------------------\n",
    "                  X N,D input design matrix\n",
    "                 yy N,  regression targets\n",
    "              alpha     scalar regularization for weights\n",
    "\n",
    "     Outputs:\n",
    "                     E  sum of squares error\n",
    "            params_bar  gradients wrt params, same format as params\n",
    "     OR\n",
    "               pred N,  predictions if only params and X are given as inputs\n",
    "    \"\"\"\n",
    "    # Unpack parameters from list\n",
    "    ww, bb, V, bk = params\n",
    "\n",
    "    # Forwards computation of cost\n",
    "    A = np.dot(X, V.T) + bk[None,:] # N,K\n",
    "    P = 1 / (1 + np.exp(-A)) # N,K\n",
    "    F = np.dot(P, ww) + bb # N,\n",
    "    if yy is None:\n",
    "        # user wants prediction rather than training signal:\n",
    "        return F\n",
    "    res = F - yy # N,\n",
    "    E = np.dot(res, res) + alpha*(np.sum(V*V) + np.dot(ww,ww)) # 1x1\n",
    "\n",
    "    # Reverse computation of gradients\n",
    "    F_bar = 2*res # N,\n",
    "    ww_bar = np.dot(P.T, F_bar) + 2*alpha*ww # K,\n",
    "    bb_bar = np.sum(F_bar) # scalar\n",
    "    P_bar = np.dot(F_bar[:,None], ww[None,:]) # N,\n",
    "    A_bar = P_bar * P * (1 - P) # N,\n",
    "    V_bar = np.dot(A_bar.T, X) + 2*alpha*V # K,\n",
    "    bk_bar = np.sum(A_bar, 0)\n",
    "\n",
    "    return E, (ww_bar, bb_bar, V_bar, bk_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mat_contents = scipy.io.loadmat(\"ct_data.mat\", squeeze_me=True)\n",
    "X_train = mat_contents['X_train']\n",
    "X_val = mat_contents['X_val']\n",
    "X_test = mat_contents['X_test']\n",
    "y_train = mat_contents['y_train']\n",
    "y_val = mat_contents['y_val']\n",
    "y_test = mat_contents['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_val   mean = -0.216009, std = 0.981421, stderr = 0.012903\n",
      "y_train mean = -0.000000, std = 0.999988, stderr = 0.004953\n"
     ]
    }
   ],
   "source": [
    "assert np.isclose(y_train.mean(),0)\n",
    "assert not np.isclose(y_val.mean(),0)\n",
    "y_val_stderr = y_val.std()/((y_val.shape[0])**0.5)\n",
    "y_train_stderr = y_train.std()/((y_train.shape[0])**0.5)\n",
    "print(\"y_val   mean = %f, std = %f, stderr = %f\" % (y_val.mean(),   y_val.std(),   y_val_stderr))\n",
    "print(\"y_train mean = %f, std = %f, stderr = %f\" % (y_train.mean(), y_train.std(), y_train_stderr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of y_train is zero within numberical rounding errors. The mean of y_val is not zero. \n",
    "The mean of y_val is approximately $-2.16\\times10^{-1}$. Its standard error is $1.29\\times10^{-2}$.\n",
    "For comparison, the mean of y_train is close $0$. Its standard error is $4.95\\times10^{-3}$.\n",
    "\n",
    "This is a misuse of stardard error of the mean (SEM) caused by confusion between SEM and standard deviation of the obervations. Standard deivation of observations, as a descriptive statistics, describes the property of observed data. As the sample size grows, standard deviation of sampled observations is approximate to the standard deviation of population. Standard deviation over y_train is approximately equal to standard deiation over y_val.\n",
    "\n",
    "SEM is estimated by standard deviation of the sampling distribution. SEM measures the dispersion of sample means around population mean. SEM only measures the dispersion for a particular sample size. As sample size increases, SEM tends to zero. SEM of y_train is smaller than SEM of y_val because y_train has more samples than y_val. Therefore, SEM should not be used to estimate the average locations in future data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant features' indices are (array([ 59,  69, 179, 189, 351]),)\n"
     ]
    }
   ],
   "source": [
    "# remove constant features\n",
    "temp = np.all(X_train==X_train[0,:], axis = 0)\n",
    "constant_feature_indices = np.where(temp==True)\n",
    "print(\"constant features' indices are\", constant_feature_indices)\n",
    "X_train = np.delete(X_train, constant_feature_indices, axis=1)\n",
    "X_val = np.delete(X_val, constant_feature_indices, axis=1)\n",
    "X_test = np.delete(X_test, constant_feature_indices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(dataset):\n",
    "    arr = np.empty(dataset.shape[1], dtype=bool)\n",
    "    for idx1 in range(dataset.shape[1]):\n",
    "        for idx2 in range(idx1+1,dataset.shape[1]):\n",
    "            arr[idx2] = np.all(dataset[:,idx1]==dataset[:,idx2])\n",
    "            arr[idx1] = np.all(dataset[:,idx1]==dataset[:,idx2])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate features' indices are [[ 76  77 185 195 283 354]]\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate features\n",
    "col_num = X_train.shape[1]\n",
    "_,idx = np.unique(X_train,axis=1, return_index=True)\n",
    "X_train = X_train[:,np.sort(idx)]\n",
    "X_val = X_val[:,np.sort(idx)]\n",
    "X_test = X_test[:,np.sort(idx)]\n",
    "\n",
    "counter = 0\n",
    "duplicate_feature_indices = np.zeros((1,col_num-X_train.shape[1]),dtype=int)\n",
    "for value in range(col_num):\n",
    "    if value not in np.sort(idx):\n",
    "        duplicate_feature_indices[0,counter]=value\n",
    "        counter+=1\n",
    "print(\"duplicate features' indices are\", duplicate_feature_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first stage, five contant features are removed. Their indices are 59, 69, 179, 189, 351.\n",
    "In the second stage, six duplicate features are removed. Their indices are 76, 77, 185, 195, 283, 354."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linreg(X, yy, alpha):\n",
    "    Phi = np.concatenate([np.ones((X.shape[0],1)), X], axis=1)\n",
    "    Phi = np.concatenate([Phi, (alpha**0.5)*np.identity(Phi.shape[1])], axis=0)\n",
    "    yy = np.concatenate([yy, np.zeros(Phi.shape[1]).T], axis=0)\n",
    "    bb = np.linalg.lstsq(Phi, yy, rcond=-1)[0][0]\n",
    "    ww = np.linalg.lstsq(Phi, yy, rcond=-1)[0][1:]\n",
    "    return ww, bb\n",
    "    \n",
    "ww_lstsq, bb_lstsq = fit_linreg(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_grad, bb_grad = fit_linreg_gradopt(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstsq train: rmse = 0.355762, val rmse = 0.420505, test rmse = 0.443915\n",
      "grad-based : rmse = 0.355756, val rmse = 0.420588, test rmse = 0.443993\n"
     ]
    }
   ],
   "source": [
    "def rmse(X,yy,ww,bb):\n",
    "    ff = np.dot(X, ww) + bb\n",
    "    rr = yy - ff\n",
    "    return (np.dot(rr.T, rr)/rr.shape[0])**0.5\n",
    "\n",
    "print(\"lstsq train: rmse = %f, val rmse = %f, test rmse = %f\" % (rmse(X_train,y_train,ww_lstsq,bb_lstsq), \n",
    "                                                                 rmse(X_val,y_val,ww_lstsq,bb_lstsq), \n",
    "                                                                 rmse(X_test,y_test,ww_lstsq,bb_lstsq)))\n",
    "print(\"grad-based : rmse = %f, val rmse = %f, test rmse = %f\" % (rmse(X_train,y_train,ww_grad,bb_grad), \n",
    "                                                                 rmse(X_val,y_val,ww_grad,bb_grad), \n",
    "                                                                 rmse(X_test,y_test,ww_grad,bb_grad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| &nbsp;                              | Train               | Val                 | Test                |\n",
    "|-------------------------------------|---------------------|---------------------|---------------------|\n",
    "| Linear regression (least squares)   | $3.56\\times10^{-1}$ | $4.21\\times10^{-1}$ | $4.44\\times10^{-1}$ |\n",
    "| Linear regression (gradient method) | $3.56\\times10^{-1}$ | $4.21\\times10^{-1}$ | $4.44\\times10^{-1}$ |\n",
    "\n",
    "Least squares and gradient-based method gave me roughly the same results but not exactly the same. The possible reason can be the step size of gradient method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate projection matrix\n",
    "X_mu = np.mean(X_train, 0)\n",
    "centred_X_train = X_train - X_mu\n",
    "V_10 = pca_zm_proj(centred_X_train, 10)\n",
    "V_100 = pca_zm_proj(centred_X_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression by least squares\n",
    "X_train_10 = np.dot(X_train, V_10)\n",
    "X_train_100 = np.dot(X_train, V_100)\n",
    "ww_10,bb_10 = fit_linreg(X_train_10,y_train,10)\n",
    "ww_100,bb_100 = fit_linreg(X_train_100,y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=10, train rmse = 0.572918, val rmse = 0.571741, test rmse = 0.553765\n",
      "K=100,train rmse = 0.410637, val rmse = 0.432863, test rmse = 0.428621\n"
     ]
    }
   ],
   "source": [
    "train_rmse_10 = rmse(X_train_10,y_train,ww_10,bb_10)\n",
    "train_rmse_100 = rmse(X_train_100,y_train,ww_100,bb_100)\n",
    "X_val_10 = np.dot(X_val,V_10)\n",
    "X_val_100 = np.dot(X_val,V_100)\n",
    "X_test_10 = np.dot(X_test,V_10)\n",
    "X_test_100 = np.dot(X_test,V_100)\n",
    "val_rmse_10 = rmse(X_val_10,y_val,ww_10,bb_10)\n",
    "val_rmse_100 = rmse(X_val_100,y_val,ww_100,bb_100)\n",
    "test_rmse_10 = rmse(X_test_10,y_test,ww_10,bb_10)\n",
    "test_rmse_100 = rmse(X_test_100,y_test,ww_100,bb_100)\n",
    "print(\"K=10, train rmse = %f, val rmse = %f, test rmse = %f\" % (train_rmse_10, val_rmse_10,  test_rmse_10))\n",
    "print(\"K=100,train rmse = %f, val rmse = %f, test rmse = %f\" % (train_rmse_100,val_rmse_100, test_rmse_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| &nbsp;                                      | Train               | Val                 | Test                |\n",
    "|---------------------------------------------|---------------------|---------------------|---------------------|\n",
    "| Linear regression (least squares) PCA K=10  | $5.73\\times10^{-1}$ | $5.72\\times10^{-1}$ | $5.54\\times10^{-1}$ |\n",
    "| Linear regression (least squares) PCA K=100 | $4.11\\times10^{-1}$ | $4.33\\times10^{-1}$ | $4.29\\times10^{-1}$ |\n",
    "| Linear regression (least squares)           | $3.56\\times10^{-1}$ | $4.21\\times10^{-1}$ | $4.44\\times10^{-1}$ |\n",
    "\n",
    "Fitting a model to high dimensional data possibly leads to overfitting. According to the table above, fitting linear regression models to high-dimensional data gives smaller training error. This is possibly a sign of overfitting. \n",
    "\n",
    "1) Too many features increases model complexity. In this questoin, we projected D-dimensional data to K-dimension. We then fit a linear regression model to this K-dimensional version data. This linear model has K weights and 1 bias. Fitting to K-dimensional data creates a model with (K+1) parameters. If K is large, we are fitting a complex model. \n",
    "\n",
    "2) When we fit a model to too many features, the ratio of features to data (K/N) gets too high. The model can identify a single datapoint by a single feature. Such model cannot well represent the underlying population. If we want to fit to more features, more training data is required. Alternatively, we reduce original dataset to low-dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axs[0,0].hist(X_train[:,45],bins=50)\n",
    "axs[0,1].hist(X_train[:,100],bins=50)\n",
    "axs[1,0].hist(X_train[:,200],bins=50)\n",
    "axs[1,1].hist(X_train[:,300],bins=50)\n",
    "for ax2 in axs:\n",
    "    for ax in ax2:\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('Number of x')\n",
    "axs[0,0].set_title('Histogram of 45th feature')\n",
    "axs[0,1].set_title('Histogram of 100th feature')\n",
    "axs[1,0].set_title('Histogram of 200th feature')\n",
    "axs[1,1].set_title('Histogram of 300th feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of values equal -0.25 and 0 is 0.803624.\n"
     ]
    }
   ],
   "source": [
    "bool_X_train = (X_train==-0.25) | (X_train==0)\n",
    "fraction = X_train[bool_X_train].shape[0] / (X_train.shape[0]*X_train.shape[1])\n",
    "print(\"Fraction of values equal -0.25 and 0 is %f.\" % fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse = 0.317842, val rmse = 0.376945, test rmse = 0.430460\n"
     ]
    }
   ],
   "source": [
    "aug_fn = lambda X: np.concatenate([X, X==0, X<0], axis=1)\n",
    "aug_X_train = aug_fn(X_train)\n",
    "aug_X_val = aug_fn(X_val)\n",
    "aug_X_test = aug_fn(X_test)\n",
    "ww_aug,bb_aug = fit_linreg(aug_X_train,y_train,10)\n",
    "\n",
    "train_rmse_aug = rmse(aug_X_train,y_train,ww_aug,bb_aug)\n",
    "val_rmse_aug = rmse(aug_X_val,y_val,ww_aug,bb_aug)\n",
    "test_rmse_aug = rmse(aug_X_test,y_test,ww_aug,bb_aug)\n",
    "print(\"train rmse = %f, val rmse = %f, test rmse = %f\" % (train_rmse_aug,val_rmse_aug,test_rmse_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most values hold value of zero. About 80.36% of features hold value of -0.25 or 0. \n",
    "\n",
    "| &nbsp;                                         | Train               | Val                 | Test                |\n",
    "|------------------------------------------------|---------------------|---------------------|---------------------|\n",
    "| Linear regression (least squares) augment data | $3.18\\times10^{-1}$ | $3.77\\times10^{-1}$ | $4.30\\times10^{-1}$ |\n",
    "\n",
    "Intuitively, when fitting to more input features, we fits a large model with more parameters to high-dimensional data. A large model has more freedom and can fit closely to data. \n",
    "\n",
    "From the histograms and the fact that most features are -0.25 or 0, it is reasonable to treat features as categorical features. We can categorize features by value into 3 categories (i.e. zeros, positves and negatives). aug_fn concatenates original $N\\times D$ input matrix with two binary matrix and returns an $N\\times3D$ augmented dataset.\n",
    "\n",
    "Suppose we categorize features into zeros and non-zeros. In a feature vector, zeros are labelled as 1, non-zeros are labelled as 1. A feature vector is then one-hot encoded as a binary feature vector with multiple labels. This gives us a binary input matrix. Similarly, we can categorize features into negatives and non-negatives. \n",
    "\n",
    "Consider $N\\times D$ X_train is a numerical representation of categorical features, we want to encode a numerical feature vector into a categorial feature vector. We encode a D-dimensional numerical vector to a 2D-dimensional binary vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "\n",
    "K = 10\n",
    "wws = np.empty((X_train.shape[1],K)) # weights of 10 classification tasks\n",
    "bbs = np.empty(K) # biases of 10 classification tasks\n",
    "mx = np.max(y_train)\n",
    "mn = np.min(y_train)\n",
    "hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    wws[:,kk], bbs[kk] = fit_logreg_gradopt(X_train, labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "prob_X_train = np.dot(X_train,wws)+bbs\n",
    "prob_X_val = np.dot(X_val,wws)+bbs\n",
    "prob_X_test = np.dot(X_test,wws)+bbs\n",
    "\n",
    "sigmoid_vec = np.vectorize(sigmoid)\n",
    "prob_X_train = sigmoid_vec(prob_X_train)\n",
    "prob_X_val = sigmoid_vec(prob_X_val)\n",
    "prob_X_test = sigmoid_vec(prob_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse = 0.138275, val rmse = 0.252189, test rmse = 0.289803\n"
     ]
    }
   ],
   "source": [
    "ww_prob,bb_prob = fit_linreg(prob_X_train, y_train, 10)\n",
    "train_rmse_prob = rmse(prob_X_train, y_train, ww_prob, bb_prob)\n",
    "val_rmse_prob = rmse(prob_X_val, y_val, ww_prob, bb_prob)\n",
    "test_rmse_prob = rmse(prob_X_test, y_test, ww_prob, bb_prob)\n",
    "print(\"train rmse = %f, val rmse = %f, test rmse = %f\" % (train_rmse_prob,val_rmse_prob,test_rmse_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| &nbsp;                       | Train               | Val                 | Test                |\n",
    "|------------------------------|---------------------|---------------------|---------------------|\n",
    "| Logistic & linear regression | $1.38\\times10^{-1}$ | $2.52\\times10^{-1}$ | $2.90\\times10^{-1}$ |\n",
    "\n",
    "PCA projects high-dimensional dataset to low-dimension. PCA changes the diemtnsion to 10 principal components with most variation but drop other components that contributes the least to variation in dataset. principal components with most variation can strongly differ relative locations of CT slices. In other words, these 10 principal components can best reconstruct the original dataset. \n",
    "\n",
    "In this question, we reduced D-dimension to 10-dimension by fitting a logistic regression model. Then, we use the ouputs from logistic regression model as inputs to fit a linear regressoin model. Suppose we use gradient optimization fit both linear and logistic models, it is not exactly fitting a neural network because errors of the second linear model does not back propagate throught the first logistic model. Precisely speaking, we fit two regression models, but we kind of reduce dimensionality by a hidden layer of 10 units. \n",
    "\n",
    "PCA is faster because PCA gives 10 linear combinations of features that matter the most. Gradient optimization is much slower. However, information that can distinguish results might be stored in low variance components. Therefore, neural networks are likely to have less training errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glorot uniform init\n",
    "def glorot_uniform_init(shape):\n",
    "    gain = 1\n",
    "    std = gain * (2./sum(shape))**0.5\n",
    "    half_width = 3.**0.5 * std\n",
    "    return np.random.uniform(low=-half_width, high=half_width, size=shape)\n",
    "\n",
    "def fit_nn_gradopt(X, yy, alpha):\n",
    "    \"\"\"\n",
    "    ww K,  hidden-output weights\n",
    "    bb     scalar output bias\n",
    "    V  K,D hidden-input weights\n",
    "    bk K,  hidden biases\n",
    "    \"\"\"\n",
    "    K = 10\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    ww = glorot_uniform_init((K,))\n",
    "    bb = np.array(0)\n",
    "    V  = glorot_uniform_init((K,D))\n",
    "    bk = np.zeros(K)\n",
    "    init = (ww,bb,V,bk)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glorot uniform init train rmse = 0.162739, val rmse = 0.422775, test rmse = 0.419927\n"
     ]
    }
   ],
   "source": [
    "ww, bb, V, bk = fit_nn_gradopt(X_train, y_train, 10)\n",
    "params = [ww,bb,V,bk]\n",
    "train_se_glorot,_ = nn_cost(params, X_train, y_train, 10)\n",
    "train_rmse_glorot = (train_se_glorot/X_train.shape[0])**0.5\n",
    "val_se_glorot,_ = nn_cost(params, X_val, y_val, 10)\n",
    "val_rmse_glorot = (val_se_glorot/X_val.shape[0])**0.5\n",
    "test_se_glorot,_ = nn_cost(params, X_test, y_test, 10)\n",
    "test_rmse_glorot = (test_se_glorot/X_test.shape[0])**0.5\n",
    "print(\"glorot uniform init train rmse = %f, val rmse = %f, test rmse = %f\" % \n",
    "      (train_rmse_glorot,val_rmse_glorot,test_rmse_glorot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q4 init\n",
    "def fit_nn_gradopt_q4(X, yy, alpha):\n",
    "    \"\"\"\n",
    "    ww K,  hidden-output weights\n",
    "    bb     scalar output bias\n",
    "    V  K,D hidden-input weights\n",
    "    bk K,  hidden biases\n",
    "    \"\"\"\n",
    "    args = (X, yy, alpha)\n",
    "    init = (ww_prob,bb_prob,wws,bbs)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q4 init train rmse = 0.162871, val rmse = 0.417746, test rmse = 0.420747\n"
     ]
    }
   ],
   "source": [
    "ww, bb, V, bk = fit_nn_gradopt(X_train, y_train, 10)\n",
    "params = [ww,bb,V,bk]\n",
    "train_se_q4,_ = nn_cost(params, X_train, y_train, 10)\n",
    "train_rmse_q4 = (train_se_q4/X_train.shape[0])**0.5\n",
    "val_se_q4,_ = nn_cost(params, X_val, y_val, 10)\n",
    "val_rmse_q4 = (val_se_q4/X_val.shape[0])**0.5\n",
    "test_se_q4,_ = nn_cost(params, X_test, y_test, 10)\n",
    "test_rmse_q4 = (test_se_q4/X_test.shape[0])**0.5\n",
    "print(\"q4 init train rmse = %f, val rmse = %f, test rmse = %f\" % \n",
    "      (train_rmse_q4,val_rmse_q4,test_rmse_q4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| &nbsp;                          | Train               | Val                 | Test                |\n",
    "|---------------------------------|---------------------|---------------------|---------------------|\n",
    "| Glorot init NN                  | $1.60\\times10^{-1}$ | $4.23\\times10^{-1}$ | $4.23\\times10^{-1}$ |\n",
    "| Q4 init NN                      | $1.61\\times10^{-1}$ | $4.24\\times10^{-1}$ | $4.17\\times10^{-1}$ |\n",
    "| Q4 logistic & linear regression | $1.38\\times10^{-1}$ | $2.52\\times10^{-1}$ | $2.90\\times10^{-1}$ |\n",
    "\n",
    "Glorot initialization and initialization with parameters in Q4 gave roughly the same errors. Glorot initialization worked slightly better. \n",
    "\n",
    "Sigmoid function saturates at tail of 0 and 1. Gradents as tails are colse to zero. During backpropagration, gradient of sigmoid is multiplied to the gradient of cost function with respect to the output of sigmoid function. This leads to hardly any update to parameters, and the learning becomes extremely slow. In order to effectively training the neural network, we need to initialize weights within a range such that derivatives are larger. \n",
    "\n",
    "No. Fitting the neural networks does not work better than the procedure in Q4. Though this neural network has the same number of parameters as Q4 model, a neural network is a more powerful model than a combination of two regressoin models. A powerful model is likely to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| &nbsp;                                         | Train               | Val                 | Test                |\n",
    "|------------------------------------------------|---------------------|---------------------|---------------------|\n",
    "| Linear regression (gradient method)            | $3.56\\times10^{-1}$ | $4.21\\times10^{-1}$ | $4.44\\times10^{-1}$ |\n",
    "| Linear regression (least squares)              | $3.56\\times10^{-1}$ | $4.21\\times10^{-1}$ | $4.44\\times10^{-1}$ |\n",
    "| Linear regression (least squares) PCA K=10     | $5.73\\times10^{-1}$ | $5.72\\times10^{-1}$ | $5.54\\times10^{-1}$ |\n",
    "| Linear regression (least squares) PCA K=100    | $4.11\\times10^{-1}$ | $4.33\\times10^{-1}$ | $4.29\\times10^{-1}$ |\n",
    "| Linear regression (least squares) augment data | $3.18\\times10^{-1}$ | $3.77\\times10^{-1}$ | $4.30\\times10^{-1}$ |\n",
    "| Q4 logistic & linear regression                | $1.38\\times10^{-1}$ | $2.52\\times10^{-1}$ | $2.90\\times10^{-1}$ |\n",
    "| Glorot init NN                                 | $1.64\\times10^{-1}$ | $4.22\\times10^{-1}$ | $4.28\\times10^{-1}$ |\n",
    "| Q4 init NN                                     | $1.65\\times10^{-1}$ | $4.39\\times10^{-1}$ | $4.28\\times10^{-1}$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that complex models tend to overfit the data. I tried adjusting the regularization coefficient by grid search alpha between 0 and 2800. It shows that alpha between 500 and 1000 gives smaller test error. I then fine search between 500 and 1000. With alpha set to approximately 800, linear regression by least squares gives the smallest test error $4.28\\times 10^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_dict = {\n",
    "    \"train\": [],\n",
    "    \"val\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "for alpha in range(0,3000,200):\n",
    "    ww_lstsq, bb_lstsq = fit_linreg(X_train, y_train, alpha)\n",
    "    rmse_dict['train'] += [rmse(X_train,y_train,ww_lstsq,bb_lstsq)]\n",
    "    rmse_dict['val'] += [rmse(X_val,y_val,ww_lstsq,bb_lstsq)]\n",
    "    rmse_dict['test'] += [rmse(X_test,y_test,ww_lstsq,bb_lstsq)]\n",
    "\n",
    "for key,value in rmse_dict.items():\n",
    "    plt.plot(range(0,3000,200),value,label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstsq train with alpha = 500: rmse = 0.371153, val rmse = 0.429326, test rmse = 0.428825\n",
      "lstsq train with alpha = 550: rmse = 0.372324, val rmse = 0.429525, test rmse = 0.428540\n",
      "lstsq train with alpha = 600: rmse = 0.373462, val rmse = 0.429736, test rmse = 0.428330\n",
      "lstsq train with alpha = 650: rmse = 0.374569, val rmse = 0.429959, test rmse = 0.428183\n",
      "lstsq train with alpha = 700: rmse = 0.375647, val rmse = 0.430195, test rmse = 0.428092\n",
      "lstsq train with alpha = 750: rmse = 0.376698, val rmse = 0.430443, test rmse = 0.428049\n",
      "lstsq train with alpha = 800: rmse = 0.377725, val rmse = 0.430702, test rmse = 0.428048\n",
      "lstsq train with alpha = 850: rmse = 0.378728, val rmse = 0.430972, test rmse = 0.428083\n",
      "lstsq train with alpha = 900: rmse = 0.379710, val rmse = 0.431253, test rmse = 0.428151\n",
      "lstsq train with alpha = 950: rmse = 0.380671, val rmse = 0.431542, test rmse = 0.428248\n"
     ]
    }
   ],
   "source": [
    "for alpha in range(500,1000,50):\n",
    "    ww_lstsq, bb_lstsq = fit_linreg(X_train, y_train, alpha)\n",
    "    print(\"lstsq train with alpha = %d: rmse = %f, val rmse = %f, test rmse = %f\" \n",
    "          % (alpha, rmse(X_train,y_train,ww_lstsq,bb_lstsq), \n",
    "             rmse(X_val,y_val,ww_lstsq,bb_lstsq), \n",
    "             rmse(X_test,y_test,ww_lstsq,bb_lstsq)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
